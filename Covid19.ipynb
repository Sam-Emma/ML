{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>avg_word</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>hastags</th>\n",
       "      <th>numerics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>train_0</td>\n",
       "      <td>The bitcoin halving is cancelled due to</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>39</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>train_1</td>\n",
       "      <td>MercyOfAllah In good times wrapped in its gran...</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>117</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>train_2</td>\n",
       "      <td>266 Days No Digital India No Murder of e learn...</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>93</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>train_3</td>\n",
       "      <td>India is likely to run out of the remaining RN...</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>3.913043</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>train_4</td>\n",
       "      <td>In these tough times the best way to grow is t...</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>121</td>\n",
       "      <td>3.692308</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                               text  target  \\\n",
       "0  train_0            The bitcoin halving is cancelled due to       1   \n",
       "1  train_1  MercyOfAllah In good times wrapped in its gran...       0   \n",
       "2  train_2  266 Days No Digital India No Murder of e learn...       1   \n",
       "3  train_3  India is likely to run out of the remaining RN...       1   \n",
       "4  train_4  In these tough times the best way to grow is t...       0   \n",
       "\n",
       "   word_count  char_count  avg_word  stopwords  hastags  numerics  \n",
       "0           7          39  4.714286          2        0         0  \n",
       "1          20         117  4.900000          7        0         0  \n",
       "2          20          93  3.700000          2        0         1  \n",
       "3          23         112  3.913043         11        0         0  \n",
       "4          26         121  3.692308         11        0         0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['word_count'] = train['text'].apply(lambda x: len(str(x).split(\" \")))\n",
    "train['char_count'] = train['text'].str.len()\n",
    "def avg_word(sentence):\n",
    "    words = sentence.split()\n",
    "    return (sum(len(word) for word in words)/len(words))\n",
    "\n",
    "train['avg_word'] = train['text'].apply(lambda x: avg_word(x))\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "train['stopwords'] = train['text'].apply(lambda x: len([x for x in x.split() if x in stop]))\n",
    "\n",
    "train['hastags'] = train['text'].apply(lambda x: len([x for x in x.split() if x.startswith('#')]))\n",
    "train['numerics'] = train['text'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>avg_word</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>hastags</th>\n",
       "      <th>numerics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>test_0</td>\n",
       "      <td>rinaldi According to the new Italian governmen...</td>\n",
       "      <td>18</td>\n",
       "      <td>128</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>test_1</td>\n",
       "      <td>In 2017 a Palestinian judge banned divorce dur...</td>\n",
       "      <td>18</td>\n",
       "      <td>113</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>test_2</td>\n",
       "      <td>Why is  explained in the video take a look</td>\n",
       "      <td>10</td>\n",
       "      <td>42</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>test_3</td>\n",
       "      <td>Ed Davey fasting for Ramadan No contest</td>\n",
       "      <td>7</td>\n",
       "      <td>39</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>test_4</td>\n",
       "      <td>Is Doja Cat good or do you just miss Nicki Minaj</td>\n",
       "      <td>11</td>\n",
       "      <td>48</td>\n",
       "      <td>3.454545</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID                                               text  word_count  \\\n",
       "0  test_0  rinaldi According to the new Italian governmen...          18   \n",
       "1  test_1  In 2017 a Palestinian judge banned divorce dur...          18   \n",
       "2  test_2         Why is  explained in the video take a look          10   \n",
       "3  test_3            Ed Davey fasting for Ramadan No contest           7   \n",
       "4  test_4   Is Doja Cat good or do you just miss Nicki Minaj          11   \n",
       "\n",
       "   char_count  avg_word  stopwords  hastags  numerics  \n",
       "0         128  6.166667          5        0         0  \n",
       "1         113  5.333333          6        0         1  \n",
       "2          42  3.666667          4        0         0  \n",
       "3          39  4.714286          1        0         0  \n",
       "4          48  3.454545          4        0         0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['word_count'] = test['text'].apply(lambda x: len(str(x).split(\" \")))\n",
    "test['char_count'] = test['text'].str.len()\n",
    "def avg_word(sentence):\n",
    "    words = sentence.split()\n",
    "    return (sum(len(word) for word in words)/len(words))\n",
    "\n",
    "test['avg_word'] = test['text'].apply(lambda x: avg_word(x))\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "test['stopwords'] = test['text'].apply(lambda x: len([x for x in x.split() if x in stop]))\n",
    "\n",
    "test['hastags'] = test['text'].apply(lambda x: len([x for x in x.split() if x.startswith('#')]))\n",
    "test['numerics'] = test['text'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text'] = train['text'].str.replace('[^\\w\\s]','')\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "train['text'] = train['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['text'] = test['text'].str.replace('[^\\w\\s]','')\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "test['text'] = test['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                        bitcoin halving cancelled due\n",
       "1    MercyOfAllah In good times wrapped granular de...\n",
       "2    266 Days No Digital India No Murder e learning...\n",
       "3    India likely run remaining RNA kits essential ...\n",
       "4    In tough times best way grow learn case teach ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = pd.Series(' '.join(train['text']).split()).value_counts()[:10]\n",
    "freq = list(freq.index)\n",
    "train['text'] = train['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "train['text'].head()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    rinaldi According new Italian government regul...\n",
       "1    In 2017 Palestinian judge banned divorce make ...\n",
       "2                        Why explained video take look\n",
       "3                          Ed Davey fasting No contest\n",
       "4                    Is Doja Cat good miss Nicki Minaj\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = pd.Series(' '.join(test['text']).split()).value_counts()[:10]\n",
    "freq = list(freq.index)\n",
    "test['text'] = test['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "test['text'].head()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                        bitcoin halving cancelled due\n",
       "1    MercyOfAllah In good times wrapped granular de...\n",
       "2    266 Days No Digital India No Murder e learning...\n",
       "3    India likely run remaining RNA kits essential ...\n",
       "4    In tough times best way grow learn case teach ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rare words removal\n",
    "freq = pd.Series(' '.join(train['text']).split()).value_counts()[-10:]\n",
    "freq = list(freq.index)\n",
    "train['text'] = train['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "train['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    rinaldi According new Italian government regul...\n",
       "1    In 2017 Palestinian judge banned divorce make ...\n",
       "2                        Why explained video take look\n",
       "3                          Ed Davey fasting No contest\n",
       "4                    Is Doja Cat good miss Nicki Minaj\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rare words removal\n",
    "freq = pd.Series(' '.join(test['text']).split()).value_counts()[-10:]\n",
    "freq = list(freq.index)\n",
    "test['text'] = test['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "test['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    rinaldi According new Italian government regul...\n",
       "1    In 2017 Palestinian judge banner divorce make ...\n",
       "2                        Why explained video take look\n",
       "3                            D Have fasting To contest\n",
       "4                      Is Sofa At good miss Sick Final\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "train['text'][:5].apply(lambda x: str(TextBlob(x).correct()))\n",
    "test['text'][:5].apply(lambda x: str(TextBlob(x).correct()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_text_preprocess(total_text, ind, col):\n",
    "    # Remove int values from text data as that might not be imp\n",
    "    if type(total_text) is not int:\n",
    "        string = \"\"\n",
    "        # replacing all special char with space\n",
    "        total_text = re.sub('[^a-zA-Z0-9\\n]', ' ', str(total_text))\n",
    "        # replacing multiple spaces with single space\n",
    "        total_text = re.sub('\\s+',' ', str(total_text))\n",
    "        # bring whole text to same lower-case scale.\n",
    "        total_text = total_text.lower()\n",
    "        \n",
    "        for word in total_text.split():\n",
    "        # if the word is a not a stop word then retain that word from text\n",
    "            if not word in stop_words:\n",
    "                string += word + \" \"\n",
    "        \n",
    "        train[col][ind] = string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "for index, row in test.iterrows():\n",
    "    if type(row['text']) is str:\n",
    "        data_text_preprocess(row['text'], index, 'text')\n",
    "\n",
    "# Below code will take some time because its huge text (took 4 minute on my 16 GB RAM system), so run it and have a cup of coffee :)\n",
    "for index, row in train.iterrows():\n",
    "    if type(row['text']) is str:\n",
    "        data_text_preprocess(row['text'], index, 'text')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique words in train data : 4800\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "# building a CountVectorizer with all the words that occured minimum 3 times in train data\n",
    "text_vectorizer = CountVectorizer(min_df=3)\n",
    "train_text_feature_onehotCoding = text_vectorizer.fit_transform(train['text'])\n",
    "test_text_feature_onehotCoding = text_vectorizer.transform(test['text'])\n",
    "# getting all the feature names (words)\n",
    "train_text_features= text_vectorizer.get_feature_names()\n",
    "\n",
    "# train_text_feature_onehotCoding.sum(axis=0).A1 will sum every row and returns (1*number of features) vector\n",
    "train_text_fea_counts = train_text_feature_onehotCoding.sum(axis=0).A1\n",
    "\n",
    "# zip(list(text_features),text_fea_counts) will zip a word with its number of times it occured\n",
    "text_fea_dict = dict(zip(list(train_text_features),train_text_fea_counts))\n",
    "\n",
    "\n",
    "print(\"Total number of unique words in train data :\", len(train_text_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique words in train data : 4800\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "# building a CountVectorizer with all the words that occured minimum 3 times in train data\n",
    "text_vectorizer = TfidfVectorizer(min_df=3)\n",
    "train_text_feature_onehotCoding = text_vectorizer.fit_transform(train['text'])\n",
    "test_text_feature_onehotCoding = text_vectorizer.transform(test['text'])\n",
    "# getting all the feature names (words)\n",
    "train_text_features= text_vectorizer.get_feature_names()\n",
    "\n",
    "# train_text_feature_onehotCoding.sum(axis=0).A1 will sum every row and returns (1*number of features) vector\n",
    "train_text_fea_counts = train_text_feature_onehotCoding.sum(axis=0).A1\n",
    "\n",
    "# zip(list(text_features),text_fea_counts) will zip a word with its number of times it occured\n",
    "text_fea_dict = dict(zip(list(train_text_features),train_text_fea_counts))\n",
    "\n",
    "\n",
    "print(\"Total number of unique words in train data :\", len(train_text_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train['safe_text'] = train['safe_text'].apply(lambda x: re.sub('<[^<]+?>', '', x))\n",
    "#train['safe_text'] = train['safe_text'].apply(lambda x: re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\"\",x))\n",
    "#train['safe_text'] = train['safe_text'].apply(lambda x: re.sub(' +', ' ', x))\n",
    "#train['safe_text'] = train['safe_text'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_text_feature_onehotCoding\n",
    "X_t = test_text_feature_onehotCoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X.toarray())\n",
    "df1 = pd.DataFrame(X_t.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeTrain = train.merge(df, left_index=True, right_index=True)\n",
    "mergeTest = test.merge(df1, left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>avg_word</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>hastags</th>\n",
       "      <th>numerics</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>...</th>\n",
       "      <th>4790</th>\n",
       "      <th>4791</th>\n",
       "      <th>4792</th>\n",
       "      <th>4793</th>\n",
       "      <th>4794</th>\n",
       "      <th>4795</th>\n",
       "      <th>4796</th>\n",
       "      <th>4797</th>\n",
       "      <th>4798</th>\n",
       "      <th>4799</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>test_0</td>\n",
       "      <td>rinaldi According new Italian government regul...</td>\n",
       "      <td>18</td>\n",
       "      <td>128</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>test_1</td>\n",
       "      <td>In 2017 Palestinian judge banned divorce make ...</td>\n",
       "      <td>18</td>\n",
       "      <td>113</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>test_2</td>\n",
       "      <td>Why explained video take look</td>\n",
       "      <td>10</td>\n",
       "      <td>42</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>test_3</td>\n",
       "      <td>Ed Davey fasting No contest</td>\n",
       "      <td>7</td>\n",
       "      <td>39</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>test_4</td>\n",
       "      <td>Is Doja Cat good miss Nicki Minaj</td>\n",
       "      <td>11</td>\n",
       "      <td>48</td>\n",
       "      <td>3.454545</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2936</td>\n",
       "      <td>test_2936</td>\n",
       "      <td>want wish Muslim members Congress HAPPY RAMADAN</td>\n",
       "      <td>13</td>\n",
       "      <td>66</td>\n",
       "      <td>4.153846</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2937</td>\n",
       "      <td>test_2937</td>\n",
       "      <td>You mean believe conspiracy involving 5G Bill ...</td>\n",
       "      <td>27</td>\n",
       "      <td>166</td>\n",
       "      <td>5.185185</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2938</td>\n",
       "      <td>test_2938</td>\n",
       "      <td>Our end persecution animals cruel This Monday ...</td>\n",
       "      <td>16</td>\n",
       "      <td>86</td>\n",
       "      <td>4.437500</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2939</td>\n",
       "      <td>test_2939</td>\n",
       "      <td>New York New Jersey California ordered nursing...</td>\n",
       "      <td>18</td>\n",
       "      <td>105</td>\n",
       "      <td>4.888889</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2940</td>\n",
       "      <td>test_2940</td>\n",
       "      <td>Rajavi We call United Nations Security Council...</td>\n",
       "      <td>20</td>\n",
       "      <td>112</td>\n",
       "      <td>4.650000</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2941 rows Ã— 4808 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID                                               text  \\\n",
       "0        test_0  rinaldi According new Italian government regul...   \n",
       "1        test_1  In 2017 Palestinian judge banned divorce make ...   \n",
       "2        test_2                      Why explained video take look   \n",
       "3        test_3                        Ed Davey fasting No contest   \n",
       "4        test_4                  Is Doja Cat good miss Nicki Minaj   \n",
       "...         ...                                                ...   \n",
       "2936  test_2936    want wish Muslim members Congress HAPPY RAMADAN   \n",
       "2937  test_2937  You mean believe conspiracy involving 5G Bill ...   \n",
       "2938  test_2938  Our end persecution animals cruel This Monday ...   \n",
       "2939  test_2939  New York New Jersey California ordered nursing...   \n",
       "2940  test_2940  Rajavi We call United Nations Security Council...   \n",
       "\n",
       "      word_count  char_count  avg_word  stopwords  hastags  numerics    0  \\\n",
       "0             18         128  6.166667          5        0         0  0.0   \n",
       "1             18         113  5.333333          6        0         1  0.0   \n",
       "2             10          42  3.666667          4        0         0  0.0   \n",
       "3              7          39  4.714286          1        0         0  0.0   \n",
       "4             11          48  3.454545          4        0         0  0.0   \n",
       "...          ...         ...       ...        ...      ...       ...  ...   \n",
       "2936          13          66  4.153846          5        0         0  0.0   \n",
       "2937          27         166  5.185185         10        0         0  0.0   \n",
       "2938          16          86  4.437500          5        0         0  0.0   \n",
       "2939          18         105  4.888889          5        0         0  0.0   \n",
       "2940          20         112  4.650000          8        0         0  0.0   \n",
       "\n",
       "        1  ...  4790  4791  4792  4793  4794  4795  4796  4797  4798  4799  \n",
       "0     0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1     0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2     0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3     0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4     0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "...   ...  ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "2936  0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2937  0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2938  0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2939  0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2940  0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[2941 rows x 4808 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mergeTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = mergeTrain\n",
    "test = mergeTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(['ID','text','target'],axis = 1)\n",
    "test = test.drop(['ID','text'],axis = 1)\n",
    "y = train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = np.sqrt(X)\n",
    "#test = np.sqrt(test)\n",
    "#from sklearn.preprocessing import MaxAbsScaler\n",
    "#scaler = MaxAbsScaler()\n",
    "#X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.float64(X)\n",
    "test = np.float64(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:20:03] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-a52bbc686dc6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mXGBRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mxg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXGBRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m34\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mxg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Make predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[0;32m    394\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 396\u001b[1;33m                               callbacks=callbacks)\n\u001b[0m\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[0;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1107\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[1;32m-> 1109\u001b[1;33m                                                     dtrain.handle))\n\u001b[0m\u001b[0;32m   1110\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "xg = XGBRegressor(random_state =34)\n",
    "xg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predsxg = xg.predict(X_test)\n",
    "\n",
    "# Score\n",
    "print(log_loss(y_test, predsxg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.051204\n",
      "0:\tlearn: 0.4980752\ttotal: 439ms\tremaining: 7m 18s\n",
      "1:\tlearn: 0.4964530\ttotal: 924ms\tremaining: 7m 41s\n",
      "2:\tlearn: 0.4949511\ttotal: 1.35s\tremaining: 7m 29s\n",
      "3:\tlearn: 0.4934931\ttotal: 1.76s\tremaining: 7m 18s\n",
      "4:\tlearn: 0.4923047\ttotal: 2.19s\tremaining: 7m 15s\n",
      "5:\tlearn: 0.4905332\ttotal: 2.62s\tremaining: 7m 13s\n",
      "6:\tlearn: 0.4889449\ttotal: 3.02s\tremaining: 7m 8s\n",
      "7:\tlearn: 0.4876448\ttotal: 3.46s\tremaining: 7m 9s\n",
      "8:\tlearn: 0.4865072\ttotal: 3.9s\tremaining: 7m 9s\n",
      "9:\tlearn: 0.4853598\ttotal: 4.33s\tremaining: 7m 8s\n",
      "10:\tlearn: 0.4842000\ttotal: 4.75s\tremaining: 7m 7s\n",
      "11:\tlearn: 0.4835050\ttotal: 5.17s\tremaining: 7m 5s\n",
      "12:\tlearn: 0.4823078\ttotal: 5.59s\tremaining: 7m 4s\n",
      "13:\tlearn: 0.4814557\ttotal: 6.02s\tremaining: 7m 4s\n",
      "14:\tlearn: 0.4802496\ttotal: 6.45s\tremaining: 7m 3s\n",
      "15:\tlearn: 0.4789545\ttotal: 6.88s\tremaining: 7m 3s\n",
      "16:\tlearn: 0.4780276\ttotal: 7.29s\tremaining: 7m 1s\n",
      "17:\tlearn: 0.4770728\ttotal: 7.71s\tremaining: 7m\n",
      "18:\tlearn: 0.4763784\ttotal: 8.14s\tremaining: 7m\n",
      "19:\tlearn: 0.4756707\ttotal: 8.54s\tremaining: 6m 58s\n",
      "20:\tlearn: 0.4748977\ttotal: 8.96s\tremaining: 6m 57s\n",
      "21:\tlearn: 0.4744215\ttotal: 9.38s\tremaining: 6m 56s\n",
      "22:\tlearn: 0.4737465\ttotal: 9.8s\tremaining: 6m 56s\n",
      "23:\tlearn: 0.4731403\ttotal: 10.2s\tremaining: 6m 55s\n",
      "24:\tlearn: 0.4725469\ttotal: 10.6s\tremaining: 6m 55s\n",
      "25:\tlearn: 0.4720617\ttotal: 11s\tremaining: 6m 53s\n",
      "26:\tlearn: 0.4713349\ttotal: 11.5s\tremaining: 6m 53s\n",
      "27:\tlearn: 0.4707031\ttotal: 11.9s\tremaining: 6m 52s\n",
      "28:\tlearn: 0.4701209\ttotal: 12.3s\tremaining: 6m 51s\n",
      "29:\tlearn: 0.4695284\ttotal: 12.7s\tremaining: 6m 51s\n",
      "30:\tlearn: 0.4688282\ttotal: 13.1s\tremaining: 6m 50s\n",
      "31:\tlearn: 0.4682835\ttotal: 13.6s\tremaining: 6m 50s\n",
      "32:\tlearn: 0.4677770\ttotal: 14s\tremaining: 6m 49s\n",
      "33:\tlearn: 0.4673157\ttotal: 14.4s\tremaining: 6m 49s\n",
      "34:\tlearn: 0.4668209\ttotal: 14.9s\tremaining: 6m 49s\n",
      "35:\tlearn: 0.4664272\ttotal: 15.3s\tremaining: 6m 49s\n",
      "36:\tlearn: 0.4659234\ttotal: 15.7s\tremaining: 6m 49s\n",
      "37:\tlearn: 0.4655159\ttotal: 16.2s\tremaining: 6m 49s\n",
      "38:\tlearn: 0.4651759\ttotal: 16.6s\tremaining: 6m 49s\n",
      "39:\tlearn: 0.4646967\ttotal: 17s\tremaining: 6m 48s\n",
      "40:\tlearn: 0.4640467\ttotal: 17.5s\tremaining: 6m 50s\n",
      "41:\tlearn: 0.4635443\ttotal: 18s\tremaining: 6m 49s\n",
      "42:\tlearn: 0.4629678\ttotal: 18.4s\tremaining: 6m 49s\n",
      "43:\tlearn: 0.4626230\ttotal: 18.8s\tremaining: 6m 48s\n",
      "44:\tlearn: 0.4622717\ttotal: 19.2s\tremaining: 6m 48s\n",
      "45:\tlearn: 0.4619025\ttotal: 19.7s\tremaining: 6m 48s\n",
      "46:\tlearn: 0.4615458\ttotal: 20.2s\tremaining: 6m 50s\n",
      "47:\tlearn: 0.4613128\ttotal: 20.8s\tremaining: 6m 53s\n",
      "48:\tlearn: 0.4608458\ttotal: 21.4s\tremaining: 6m 55s\n",
      "49:\tlearn: 0.4605784\ttotal: 21.9s\tremaining: 6m 55s\n",
      "50:\tlearn: 0.4602891\ttotal: 22.4s\tremaining: 6m 56s\n",
      "51:\tlearn: 0.4599958\ttotal: 22.9s\tremaining: 6m 57s\n",
      "52:\tlearn: 0.4595875\ttotal: 23.4s\tremaining: 6m 58s\n",
      "53:\tlearn: 0.4593650\ttotal: 23.9s\tremaining: 6m 58s\n",
      "54:\tlearn: 0.4591494\ttotal: 24.4s\tremaining: 6m 59s\n",
      "55:\tlearn: 0.4588575\ttotal: 25s\tremaining: 7m 1s\n",
      "56:\tlearn: 0.4586721\ttotal: 25.6s\tremaining: 7m 3s\n",
      "57:\tlearn: 0.4583433\ttotal: 26.1s\tremaining: 7m 4s\n",
      "58:\tlearn: 0.4578371\ttotal: 26.6s\tremaining: 7m 4s\n",
      "59:\tlearn: 0.4574382\ttotal: 27.2s\tremaining: 7m 6s\n",
      "60:\tlearn: 0.4571311\ttotal: 27.8s\tremaining: 7m 8s\n",
      "61:\tlearn: 0.4568640\ttotal: 28.4s\tremaining: 7m 9s\n",
      "62:\tlearn: 0.4565776\ttotal: 28.9s\tremaining: 7m 10s\n",
      "63:\tlearn: 0.4562413\ttotal: 29.7s\tremaining: 7m 13s\n",
      "64:\tlearn: 0.4561407\ttotal: 30.4s\tremaining: 7m 16s\n",
      "65:\tlearn: 0.4558266\ttotal: 30.9s\tremaining: 7m 16s\n",
      "66:\tlearn: 0.4556249\ttotal: 31.4s\tremaining: 7m 17s\n",
      "67:\tlearn: 0.4553725\ttotal: 32.1s\tremaining: 7m 19s\n",
      "68:\tlearn: 0.4551462\ttotal: 32.7s\tremaining: 7m 20s\n",
      "69:\tlearn: 0.4549261\ttotal: 33.2s\tremaining: 7m 21s\n",
      "70:\tlearn: 0.4546708\ttotal: 33.8s\tremaining: 7m 21s\n",
      "71:\tlearn: 0.4543639\ttotal: 34.3s\tremaining: 7m 22s\n",
      "72:\tlearn: 0.4541610\ttotal: 35s\tremaining: 7m 24s\n",
      "73:\tlearn: 0.4538984\ttotal: 35.7s\tremaining: 7m 27s\n",
      "74:\tlearn: 0.4536404\ttotal: 36.4s\tremaining: 7m 29s\n",
      "75:\tlearn: 0.4534080\ttotal: 37.1s\tremaining: 7m 30s\n",
      "76:\tlearn: 0.4532095\ttotal: 37.7s\tremaining: 7m 31s\n",
      "77:\tlearn: 0.4529562\ttotal: 38.4s\tremaining: 7m 33s\n",
      "78:\tlearn: 0.4527556\ttotal: 38.8s\tremaining: 7m 32s\n",
      "79:\tlearn: 0.4525217\ttotal: 39.3s\tremaining: 7m 31s\n",
      "80:\tlearn: 0.4522388\ttotal: 40s\tremaining: 7m 33s\n",
      "81:\tlearn: 0.4520869\ttotal: 40.6s\tremaining: 7m 34s\n",
      "82:\tlearn: 0.4519133\ttotal: 41.2s\tremaining: 7m 35s\n",
      "83:\tlearn: 0.4517495\ttotal: 41.9s\tremaining: 7m 37s\n",
      "84:\tlearn: 0.4515327\ttotal: 42.5s\tremaining: 7m 37s\n",
      "85:\tlearn: 0.4512058\ttotal: 43s\tremaining: 7m 36s\n",
      "86:\tlearn: 0.4509801\ttotal: 43.5s\tremaining: 7m 37s\n",
      "87:\tlearn: 0.4508265\ttotal: 44.2s\tremaining: 7m 38s\n",
      "88:\tlearn: 0.4506696\ttotal: 44.8s\tremaining: 7m 38s\n",
      "89:\tlearn: 0.4504627\ttotal: 45.3s\tremaining: 7m 38s\n",
      "90:\tlearn: 0.4503122\ttotal: 45.9s\tremaining: 7m 38s\n",
      "91:\tlearn: 0.4501904\ttotal: 46.6s\tremaining: 7m 39s\n",
      "92:\tlearn: 0.4500170\ttotal: 47.1s\tremaining: 7m 39s\n",
      "93:\tlearn: 0.4498676\ttotal: 47.6s\tremaining: 7m 39s\n",
      "94:\tlearn: 0.4497124\ttotal: 48.2s\tremaining: 7m 39s\n",
      "95:\tlearn: 0.4495504\ttotal: 48.7s\tremaining: 7m 38s\n",
      "96:\tlearn: 0.4493591\ttotal: 49.1s\tremaining: 7m 37s\n",
      "97:\tlearn: 0.4492018\ttotal: 49.6s\tremaining: 7m 36s\n",
      "98:\tlearn: 0.4489493\ttotal: 50.1s\tremaining: 7m 35s\n",
      "99:\tlearn: 0.4486947\ttotal: 50.8s\tremaining: 7m 37s\n",
      "100:\tlearn: 0.4485299\ttotal: 51.4s\tremaining: 7m 37s\n",
      "101:\tlearn: 0.4483580\ttotal: 52s\tremaining: 7m 38s\n",
      "102:\tlearn: 0.4481769\ttotal: 52.7s\tremaining: 7m 38s\n",
      "103:\tlearn: 0.4480534\ttotal: 53.6s\tremaining: 7m 42s\n",
      "104:\tlearn: 0.4479226\ttotal: 54.8s\tremaining: 7m 46s\n",
      "105:\tlearn: 0.4476030\ttotal: 55.4s\tremaining: 7m 47s\n",
      "106:\tlearn: 0.4473876\ttotal: 56s\tremaining: 7m 47s\n",
      "107:\tlearn: 0.4472359\ttotal: 56.8s\tremaining: 7m 49s\n",
      "108:\tlearn: 0.4470695\ttotal: 57.4s\tremaining: 7m 48s\n",
      "109:\tlearn: 0.4469764\ttotal: 58s\tremaining: 7m 49s\n",
      "110:\tlearn: 0.4467481\ttotal: 58.7s\tremaining: 7m 50s\n",
      "111:\tlearn: 0.4464858\ttotal: 59.3s\tremaining: 7m 50s\n",
      "112:\tlearn: 0.4463012\ttotal: 59.8s\tremaining: 7m 49s\n",
      "113:\tlearn: 0.4460577\ttotal: 1m\tremaining: 7m 48s\n",
      "114:\tlearn: 0.4459336\ttotal: 1m\tremaining: 7m 47s\n",
      "115:\tlearn: 0.4457916\ttotal: 1m 1s\tremaining: 7m 47s\n",
      "116:\tlearn: 0.4455813\ttotal: 1m 1s\tremaining: 7m 47s\n",
      "117:\tlearn: 0.4454554\ttotal: 1m 2s\tremaining: 7m 47s\n",
      "118:\tlearn: 0.4453489\ttotal: 1m 3s\tremaining: 7m 48s\n",
      "119:\tlearn: 0.4451869\ttotal: 1m 3s\tremaining: 7m 47s\n",
      "120:\tlearn: 0.4450645\ttotal: 1m 4s\tremaining: 7m 48s\n",
      "121:\tlearn: 0.4449228\ttotal: 1m 5s\tremaining: 7m 49s\n",
      "122:\tlearn: 0.4447324\ttotal: 1m 5s\tremaining: 7m 48s\n",
      "123:\tlearn: 0.4444187\ttotal: 1m 6s\tremaining: 7m 49s\n",
      "124:\tlearn: 0.4442750\ttotal: 1m 7s\tremaining: 7m 51s\n",
      "125:\tlearn: 0.4440381\ttotal: 1m 7s\tremaining: 7m 50s\n",
      "126:\tlearn: 0.4438372\ttotal: 1m 8s\tremaining: 7m 50s\n",
      "127:\tlearn: 0.4436676\ttotal: 1m 8s\tremaining: 7m 49s\n",
      "128:\tlearn: 0.4435259\ttotal: 1m 9s\tremaining: 7m 49s\n",
      "129:\tlearn: 0.4432013\ttotal: 1m 10s\tremaining: 7m 48s\n",
      "130:\tlearn: 0.4430712\ttotal: 1m 10s\tremaining: 7m 47s\n",
      "131:\tlearn: 0.4429104\ttotal: 1m 11s\tremaining: 7m 48s\n",
      "132:\tlearn: 0.4426361\ttotal: 1m 11s\tremaining: 7m 46s\n",
      "133:\tlearn: 0.4425070\ttotal: 1m 12s\tremaining: 7m 45s\n",
      "134:\tlearn: 0.4423552\ttotal: 1m 12s\tremaining: 7m 44s\n",
      "135:\tlearn: 0.4420447\ttotal: 1m 13s\tremaining: 7m 44s\n",
      "136:\tlearn: 0.4419107\ttotal: 1m 13s\tremaining: 7m 44s\n",
      "137:\tlearn: 0.4417542\ttotal: 1m 14s\tremaining: 7m 42s\n",
      "138:\tlearn: 0.4415993\ttotal: 1m 14s\tremaining: 7m 41s\n",
      "139:\tlearn: 0.4414032\ttotal: 1m 15s\tremaining: 7m 41s\n",
      "140:\tlearn: 0.4412257\ttotal: 1m 15s\tremaining: 7m 40s\n",
      "141:\tlearn: 0.4410875\ttotal: 1m 16s\tremaining: 7m 40s\n",
      "142:\tlearn: 0.4409847\ttotal: 1m 16s\tremaining: 7m 40s\n",
      "143:\tlearn: 0.4407983\ttotal: 1m 17s\tremaining: 7m 40s\n",
      "144:\tlearn: 0.4406528\ttotal: 1m 17s\tremaining: 7m 39s\n",
      "145:\tlearn: 0.4405039\ttotal: 1m 18s\tremaining: 7m 40s\n",
      "146:\tlearn: 0.4403533\ttotal: 1m 19s\tremaining: 7m 40s\n",
      "147:\tlearn: 0.4402276\ttotal: 1m 19s\tremaining: 7m 39s\n",
      "148:\tlearn: 0.4401028\ttotal: 1m 20s\tremaining: 7m 39s\n",
      "149:\tlearn: 0.4399802\ttotal: 1m 20s\tremaining: 7m 38s\n",
      "150:\tlearn: 0.4397639\ttotal: 1m 21s\tremaining: 7m 38s\n",
      "151:\tlearn: 0.4396145\ttotal: 1m 22s\tremaining: 7m 37s\n",
      "152:\tlearn: 0.4394286\ttotal: 1m 22s\tremaining: 7m 36s\n",
      "153:\tlearn: 0.4393180\ttotal: 1m 23s\tremaining: 7m 36s\n",
      "154:\tlearn: 0.4392060\ttotal: 1m 23s\tremaining: 7m 36s\n",
      "155:\tlearn: 0.4390753\ttotal: 1m 24s\tremaining: 7m 37s\n",
      "156:\tlearn: 0.4389031\ttotal: 1m 25s\tremaining: 7m 37s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157:\tlearn: 0.4387625\ttotal: 1m 25s\tremaining: 7m 37s\n",
      "158:\tlearn: 0.4385970\ttotal: 1m 26s\tremaining: 7m 37s\n",
      "159:\tlearn: 0.4384276\ttotal: 1m 26s\tremaining: 7m 36s\n",
      "160:\tlearn: 0.4381468\ttotal: 1m 27s\tremaining: 7m 36s\n",
      "161:\tlearn: 0.4379591\ttotal: 1m 28s\tremaining: 7m 35s\n",
      "162:\tlearn: 0.4378182\ttotal: 1m 28s\tremaining: 7m 35s\n",
      "163:\tlearn: 0.4376313\ttotal: 1m 29s\tremaining: 7m 34s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-1c7afce5ead8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcatboost\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcbt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcbt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCatBoostRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m34\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcbt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Make predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, cat_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[0;32m   4478\u001b[0m                          \u001b[0muse_best_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4479\u001b[0m                          \u001b[0mverbose_eval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4480\u001b[1;33m                          save_snapshot, snapshot_file, snapshot_interval, init_model)\n\u001b[0m\u001b[0;32m   4481\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4482\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mntree_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mntree_end\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, cat_features, text_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[0;32m   1730\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1731\u001b[0m                 \u001b[0mallow_clear_pool\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1732\u001b[1;33m                 \u001b[0mtrain_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"init_model\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1733\u001b[0m             )\n\u001b[0;32m   1734\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_train\u001b[1;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[0;32m   1253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1254\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1255\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_object\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0minit_model\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1256\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_trained_model_attributes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import catboost as cbt\n",
    "cbt = cbt.CatBoostRegressor(random_state = 34)\n",
    "cbt.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predscbt = cbt.predict(X_test)\n",
    "\n",
    "# Score\n",
    "print(log_loss(y_test, predscbt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6332995801777062\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "lgb = lgb.LGBMRegressor(random_state = 34, n_estimators = 15)\n",
    "lgb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predslgm = lgb.predict(X_test)\n",
    "\n",
    "# Score\n",
    "print(mean_squared_error(y_test, predslgm)**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "seed = 7\n",
    "#kfold = model_selection.KFold(n_splits = 10, random_state = seed)\n",
    "model1 = BaggingRegressor(base_estimator = rfc, n_estimators =20,random_state =seed)\n",
    "model1.fit(X_train, y_train)\n",
    "preds = model1.predict(X_test)\n",
    "# Score\n",
    "print(mean_squared_error(y_test, preds)**0.5)\n",
    "\n",
    "#results = model_selection.cross_val_score(model1,X,y,cv = kfold)\n",
    "#print (results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.631942228621704\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "seed = 7\n",
    "#kfold = model_selection.KFold(n_splits = 10, random_state = seed)\n",
    "model2 = BaggingRegressor(base_estimator = lgb, n_estimators =15,random_state =seed)\n",
    "model2.fit(X_train, y_train)\n",
    "preds = model2.predict(X_test)\n",
    "# Score\n",
    "print(mean_squared_error(y_test, preds)**0.5)\n",
    "#results = model_selection.cross_val_score(model1,X,y,cv = kfold)\n",
    "#print (results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "No matching signature found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-7e7021ef2d3b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#kfold = model_selection.KFold(n_splits = 10, random_state = seed)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBaggingRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_estimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m101\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mmodel4\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel4\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\bagging.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    239\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m         \"\"\"\n\u001b[1;32m--> 241\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_parallel_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\bagging.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, max_samples, max_depth, sample_weight)\u001b[0m\n\u001b[0;32m    377\u001b[0m                 \u001b[0mtotal_n_estimators\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m                 verbose=self.verbose)\n\u001b[1;32m--> 379\u001b[1;33m             for i in range(n_jobs))\n\u001b[0m\u001b[0;32m    380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m         \u001b[1;31m# Reduce\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    919\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 921\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\bagging.py\u001b[0m in \u001b[0;36m_parallel_build_estimators\u001b[1;34m(n_estimators, ensemble, X, y, sample_weight, seeds, total_n_estimators, verbose)\u001b[0m\n\u001b[0;32m    106\u001b[0m                 \u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnot_indices_mask\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, cat_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[0;32m   4478\u001b[0m                          \u001b[0muse_best_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4479\u001b[0m                          \u001b[0mverbose_eval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4480\u001b[1;33m                          save_snapshot, snapshot_file, snapshot_interval, init_model)\n\u001b[0m\u001b[0;32m   4481\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4482\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mntree_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mntree_end\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, cat_features, text_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[0;32m   1718\u001b[0m             \u001b[0muse_best_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1719\u001b[0m             \u001b[0mcolumn_description\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1720\u001b[1;33m             \u001b[0msave_snapshot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msnapshot_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msnapshot_interval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1721\u001b[0m         )\n\u001b[0;32m   1722\u001b[0m         \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"params\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_prepare_train_params\u001b[1;34m(self, X, y, cat_features, text_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[0;32m   1606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1607\u001b[0m         train_pool = _build_train_pool(X, y, cat_features, text_features, pairs, sample_weight, group_id,\n\u001b[1;32m-> 1608\u001b[1;33m                                        group_weight, subgroup_id, pairs_weight, baseline, column_description)\n\u001b[0m\u001b[0;32m   1609\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_empty_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1610\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mCatBoostError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"X is empty.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_build_train_pool\u001b[1;34m(X, y, cat_features, text_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, column_description)\u001b[0m\n\u001b[0;32m   1001\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mCatBoostError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y has not initialized in fit(): X is not catboost.Pool object, y must be not None in fit().\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1002\u001b[0m         train_pool = Pool(X, y, cat_features=cat_features, text_features=text_features, pairs=pairs, weight=sample_weight, group_id=group_id,\n\u001b[1;32m-> 1003\u001b[1;33m                           group_weight=group_weight, subgroup_id=subgroup_id, pairs_weight=pairs_weight, baseline=baseline)\n\u001b[0m\u001b[0;32m   1004\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, label, cat_features, text_features, column_description, pairs, delimiter, has_header, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, feature_names, thread_count)\u001b[0m\n\u001b[0;32m    382\u001b[0m                     )\n\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpairs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubgroup_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpairs_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbaseline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_init\u001b[1;34m(self, data, label, cat_features, text_features, pairs, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, feature_names, thread_count)\u001b[0m\n\u001b[0;32m    982\u001b[0m             \u001b[0mbaseline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbaseline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msamples_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    983\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_baseline_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbaseline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 984\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_pool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpairs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubgroup_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpairs_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbaseline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._PoolBase._init_pool\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._PoolBase._init_pool\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._PoolBase._init_features_order_layout_pool\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._PoolBase._set_label_features_order\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost.__pyx_fused_cpdef\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: No matching signature found"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "seed = 7\n",
    "#kfold = model_selection.KFold(n_splits = 10, random_state = seed)\n",
    "model4 = BaggingRegressor(base_estimator = cbt,random_state =seed,n_estimators = 101)\n",
    "model4.fit(X_train, y_train)\n",
    "preds = model4.predict(X_test)\n",
    "# Score\n",
    "print(mean_squared_error(y_test, preds)**0.5)\n",
    "#results = model_selection.cross_val_score(model1,X,y,cv = kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "seed = 7\n",
    "#kfold = model_selection.KFold(n_splits = 10, random_state = seed)\n",
    "model3 = BaggingRegressor(base_estimator = xg, n_estimators =20,random_state =seed)\n",
    "model3.fit(X_train, y_train)\n",
    "preds = model3.predict(X_test)\n",
    "# Score\n",
    "print(mean_squared_error(y_test, preds)**0.5)\n",
    "#results = model_selection.cross_val_score(model1,X,y,cv = kfold)\n",
    "#print (results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "estimators = []\n",
    "estimators.append(('catboost',cbt))\n",
    "estimators.append(('lgb',lgb))\n",
    "#estimators.append(('rfc',rfc))\n",
    "estimators.append(('xgb',xg))\n",
    "ensemble = VotingRegressor(estimators)\n",
    "ensemble.fit(X_train, y_train)\n",
    "preds = ensemble.predict(X_test)\n",
    "# Score\n",
    "print(mean_squared_error(y_test, preds)**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens = ensemble.predict(X_test)\n",
    "\n",
    "#vot =  model1.predict(X_test)\n",
    "vot2 = model2.predict(X_test)\n",
    "vot3 = model3.predict(X_test)\n",
    "vot4 = model4.predict(X_test)\n",
    "stacked_predictions = np.column_stack((predscbt,ens,vot3,vot2,vot4,predslgm))#predslgm,preds,vot,vot3\n",
    "from sklearn.linear_model import LinearRegression\n",
    "meta_model = LinearRegression()\n",
    "meta_model.fit(stacked_predictions,y_test)\n",
    "final = meta_model.predict(stacked_predictions)\n",
    "print(mean_squared_error(y_test, final)**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testpredcbt = cbt.predict(test)\n",
    "testpredlgm = lgb.predict(test)\n",
    "#testpredxgb = xg.predict(test)\n",
    "testensemble = ensemble.predict(test)\n",
    "#testvoting = model1.predict(test)\n",
    "testvoting2 = model2.predict(test)\n",
    "testvoting3 = model3.predict(test)#testpredlgm,testpredxgb,testvoting,testvoting3\n",
    "testvoting4 = model4.predict(test)\n",
    "test_stacked = np.column_stack((testpredcbt,testensemble,testvoting3,testvoting2,testvoting4,testpredlgm))\n",
    "from sklearn.linear_model import LinearRegression\n",
    "meta_model = LinearRegression()\n",
    "meta_model.fit(stacked_predictions,y_test)\n",
    "predictions = meta_model.predict(test_stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_predictions = np.column_stack((predscbt,predslgm,preds,rfcpreds))\n",
    "from sklearn.linear_model import LinearRegression\n",
    "meta_model = LinearRegression()\n",
    "meta_model.fit(stacked_predictions,y_test)\n",
    "final = meta_model.predict(stacked_predictions)\n",
    "print(mean_squared_error(y_test, final)**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testpredcbt = cbt.predict(test)\n",
    "testpredlgb = lgb.predict(test)\n",
    "testpredxgb = xg.predict(test)\n",
    "testpredrfc = rfc.predict(test)\n",
    "test_stacked = np.column_stack((testpredcbt,testpredlgb,testpredxgb,testpredrfc))\n",
    "from sklearn.linear_model import LinearRegression\n",
    "meta_model = LinearRegression()\n",
    "meta_model.fit(stacked_predictions,y_test)\n",
    "predictions = meta_model.predict(test_stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = pd.read_csv('SampleSubmission.csv')\n",
    "ss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss['label'] = predictions\n",
    "ss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.to_csv('4th_vaccine.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
